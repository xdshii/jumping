"""
å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å—

è¯¥æ¨¡å—æä¾›å…¨é¢çš„å›¾åƒè´¨é‡è¯„ä¼°åŠŸèƒ½ï¼Œç”¨äºè¯„ä¼°éšç§ä¿æŠ¤ç®—æ³•
å¯¹å›¾åƒè§†è§‰è´¨é‡çš„å½±å“ï¼Œç¡®ä¿ä¿æŠ¤æ•ˆæœä¸å›¾åƒè´¨é‡çš„å¹³è¡¡ã€‚

åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æ„ŸçŸ¥è´¨é‡è¯„ä¼° (LPIPS)
2. ä¼ ç»Ÿè´¨é‡æŒ‡æ ‡ (PSNR, SSIM, MSE)
3. ç»“æ„ç›¸ä¼¼æ€§åˆ†æ
4. æ‰¹é‡è´¨é‡è¯„ä¼°
5. è´¨é‡æŠ¥å‘Šç”Ÿæˆå’Œå¯è§†åŒ–

åŸºäºè®¡ç®—æœºè§†è§‰ä¸­çš„æ ‡å‡†å›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ã€‚

ä½œè€…: AI Privacy Protection System
æ—¥æœŸ: 2025-07-28
"""

import logging
from typing import List, Dict, Optional, Tuple, Any, Union
from pathlib import Path
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
import cv2
import json
from datetime import datetime
from dataclasses import dataclass
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import mean_squared_error as mse

try:
    import lpips
    LPIPS_AVAILABLE = True
except ImportError:
    LPIPS_AVAILABLE = False
    logging.warning("LPIPSåº“ä¸å¯ç”¨ï¼Œæ„ŸçŸ¥è´¨é‡è¯„ä¼°åŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    from ..utils.image_utils import ImageProcessor
    from ..losses.lpips_loss import create_lpips_loss
except ImportError:
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    from utils.image_utils import ImageProcessor
    from losses.lpips_loss import create_lpips_loss

logger = logging.getLogger(__name__)

@dataclass
class QualityMetrics:
    """å›¾åƒè´¨é‡æŒ‡æ ‡æ•°æ®ç±»"""
    lpips: Optional[float] = None
    psnr: Optional[float] = None
    ssim: Optional[float] = None
    mse: Optional[float] = None
    mae: Optional[float] = None
    structural_similarity: Optional[float] = None
    perceptual_distance: Optional[float] = None
    overall_score: Optional[float] = None

@dataclass
class QualityEvaluationResult:
    """è´¨é‡è¯„ä¼°ç»“æœæ•°æ®ç±»"""
    image_pair_id: str
    metrics: QualityMetrics
    image_size: Tuple[int, int]
    color_channels: int
    metadata: Optional[Dict[str, Any]] = None

class ImageQualityEvaluator:
    """å›¾åƒè´¨é‡è¯„ä¼°å™¨"""
    
    def __init__(
        self,
        lpips_net: str = "alex",
        lpips_version: str = "0.1",
        device: str = None,
        enable_lpips: bool = True
    ):
        """
        åˆå§‹åŒ–å›¾åƒè´¨é‡è¯„ä¼°å™¨
        
        Args:
            lpips_net: LPIPSç½‘ç»œç±»å‹ ("alex", "vgg", "squeeze")
            lpips_version: LPIPSç‰ˆæœ¬
            device: è®¾å¤‡
            enable_lpips: æ˜¯å¦è®¡ç®—LPIPS
        """
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.compute_lpips = enable_lpips and LPIPS_AVAILABLE
        
        # åˆå§‹åŒ–å·¥å…·
        self.image_processor = ImageProcessor()
        
        # åˆå§‹åŒ–LPIPS
        self.lpips_model = None
        if self.compute_lpips:
            try:
                self.lpips_model = create_lpips_loss(
                    net=lpips_net,
                    version=lpips_version,
                    use_gpu=(self.device == "cuda")
                )
                logger.info(f"LPIPSæ¨¡å‹åŠ è½½æˆåŠŸ: {lpips_net} v{lpips_version}")
            except Exception as e:
                logger.warning(f"LPIPSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.compute_lpips = False
        
        logger.info(f"å›¾åƒè´¨é‡è¯„ä¼°å™¨åˆå§‹åŒ–: è®¾å¤‡={self.device}, LPIPS={self.compute_lpips}")
    
    def preprocess_images(
        self,
        img1: Union[torch.Tensor, np.ndarray, str],
        img2: Union[torch.Tensor, np.ndarray, str]
    ) -> Tuple[np.ndarray, np.ndarray, torch.Tensor, torch.Tensor]:
        """
        é¢„å¤„ç†å›¾åƒå¯¹
        
        Args:
            img1: ç¬¬ä¸€å¼ å›¾åƒ
            img2: ç¬¬äºŒå¼ å›¾åƒ
            
        Returns:
            (img1_np, img2_np, img1_tensor, img2_tensor)
        """
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆç”¨äºä¼ ç»ŸæŒ‡æ ‡ï¼‰
        if isinstance(img1, str):
            img1_pil = Image.open(img1).convert('RGB')
            img1_np = np.array(img1_pil)
        elif isinstance(img1, torch.Tensor):
            img1_np = self.image_processor.tensor_to_numpy(img1)
        else:
            img1_np = img1
        
        if isinstance(img2, str):
            img2_pil = Image.open(img2).convert('RGB')
            img2_np = np.array(img2_pil)
        elif isinstance(img2, torch.Tensor):
            img2_np = self.image_processor.tensor_to_numpy(img2)
        else:
            img2_np = img2
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if img1_np.shape != img2_np.shape:
            min_h = min(img1_np.shape[0], img2_np.shape[0])
            min_w = min(img1_np.shape[1], img2_np.shape[1])
            img1_np = cv2.resize(img1_np, (min_w, min_h))
            img2_np = cv2.resize(img2_np, (min_w, min_h))
        
        # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆç”¨äºLPIPSï¼‰
        # numpy -> PIL -> tensor è½¬æ¢é“¾
        img1_pil = self.image_processor.numpy_to_pil(img1_np)
        img2_pil = self.image_processor.numpy_to_pil(img2_np)
        img1_tensor = self.image_processor.pil_to_tensor(img1_pil).to(self.device)
        img2_tensor = self.image_processor.pil_to_tensor(img2_pil).to(self.device)
        
        # ç¡®ä¿å¼ é‡åœ¨[0,1]èŒƒå›´å†…
        if img1_tensor.max() > 1.1 or img2_tensor.max() > 1.1:
            img1_tensor = img1_tensor / 255.0
            img2_tensor = img2_tensor / 255.0
        
        return img1_np, img2_np, img1_tensor, img2_tensor
    
    def _compute_lpips(
        self,
        img1_tensor: torch.Tensor,
        img2_tensor: torch.Tensor
    ) -> float:
        """
        è®¡ç®—LPIPSæ„ŸçŸ¥è·ç¦»
        
        Args:
            img1_tensor: ç¬¬ä¸€å¼ å›¾åƒå¼ é‡
            img2_tensor: ç¬¬äºŒå¼ å›¾åƒå¼ é‡
            
        Returns:
            LPIPSè·ç¦»å€¼
        """
        if not self.compute_lpips or self.lpips_model is None:
            return None
        
        try:
            with torch.no_grad():
                # ç¡®ä¿å¼ é‡ç»´åº¦æ­£ç¡® [B, C, H, W]
                if img1_tensor.dim() == 3:
                    img1_tensor = img1_tensor.unsqueeze(0)
                if img2_tensor.dim() == 3:
                    img2_tensor = img2_tensor.unsqueeze(0)
                
                lpips_distance = self.lpips_model(img1_tensor, img2_tensor)
                return lpips_distance.item()
        except Exception as e:
            logger.warning(f"LPIPSè®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_psnr(
        self,
        img1_np: np.ndarray,
        img2_np: np.ndarray
    ) -> float:
        """
        è®¡ç®—PSNR (Peak Signal-to-Noise Ratio)
        
        Args:
            img1_np: ç¬¬ä¸€å¼ å›¾åƒæ•°ç»„
            img2_np: ç¬¬äºŒå¼ å›¾åƒæ•°ç»„
            
        Returns:
            PSNRå€¼ (dB)
        """
        try:
            # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´
            if img1_np.dtype != np.uint8:
                img1_np = (img1_np * 255).astype(np.uint8)
            if img2_np.dtype != np.uint8:
                img2_np = (img2_np * 255).astype(np.uint8)
            
            return psnr(img1_np, img2_np, data_range=255)
        except Exception as e:
            logger.warning(f"PSNRè®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_ssim(
        self,
        img1_np: np.ndarray,
        img2_np: np.ndarray
    ) -> float:
        """
        è®¡ç®—SSIM (Structural Similarity Index)
        
        Args:
            img1_np: ç¬¬ä¸€å¼ å›¾åƒæ•°ç»„
            img2_np: ç¬¬äºŒå¼ å›¾åƒæ•°ç»„
            
        Returns:
            SSIMå€¼ [0, 1]
        """
        try:
            # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´
            if img1_np.dtype != np.uint8:
                img1_np = (img1_np * 255).astype(np.uint8)
            if img2_np.dtype != np.uint8:
                img2_np = (img2_np * 255).astype(np.uint8)
            
            # å¯¹äºå½©è‰²å›¾åƒï¼Œè®¡ç®—æ¯ä¸ªé€šé“çš„SSIMç„¶åå¹³å‡
            if len(img1_np.shape) == 3:
                ssim_values = []
                for channel in range(img1_np.shape[2]):
                    ssim_val = ssim(
                        img1_np[:, :, channel],
                        img2_np[:, :, channel],
                        data_range=255
                    )
                    ssim_values.append(ssim_val)
                return np.mean(ssim_values)
            else:
                return ssim(img1_np, img2_np, data_range=255)
        except Exception as e:
            logger.warning(f"SSIMè®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_mse(
        self,
        img1_np: np.ndarray,
        img2_np: np.ndarray
    ) -> float:
        """
        è®¡ç®—MSE (Mean Squared Error)
        
        Args:
            img1_np: ç¬¬ä¸€å¼ å›¾åƒæ•°ç»„
            img2_np: ç¬¬äºŒå¼ å›¾åƒæ•°ç»„
            
        Returns:
            MSEå€¼
        """
        try:
            # è½¬æ¢ä¸ºæµ®ç‚¹æ•°ä»¥é¿å…æº¢å‡º
            img1_float = img1_np.astype(np.float64)
            img2_float = img2_np.astype(np.float64)
            
            return mse(img1_float, img2_float)
        except Exception as e:
            logger.warning(f"MSEè®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_mae(
        self,
        img1_np: np.ndarray,
        img2_np: np.ndarray
    ) -> float:
        """
        è®¡ç®—MAE (Mean Absolute Error)
        
        Args:
            img1_np: ç¬¬ä¸€å¼ å›¾åƒæ•°ç»„
            img2_np: ç¬¬äºŒå¼ å›¾åƒæ•°ç»„
            
        Returns:
            MAEå€¼
        """
        try:
            # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            img1_float = img1_np.astype(np.float64)
            img2_float = img2_np.astype(np.float64)
            
            return np.mean(np.abs(img1_float - img2_float))
        except Exception as e:
            logger.warning(f"MAEè®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_overall_score(
        self,
        metrics: QualityMetrics,
        weights: Optional[Dict[str, float]] = None
    ) -> float:
        """
        è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
        
        Args:
            metrics: è´¨é‡æŒ‡æ ‡
            weights: å„æŒ‡æ ‡æƒé‡
            
        Returns:
            ç»¼åˆåˆ†æ•° [0, 1]ï¼Œè¶Šé«˜è¶Šå¥½
        """
        if weights is None:
            weights = {
                'lpips': 0.4,    # LPIPSè¶Šå°è¶Šå¥½
                'ssim': 0.3,     # SSIMè¶Šå¤§è¶Šå¥½
                'psnr': 0.2,     # PSNRè¶Šå¤§è¶Šå¥½
                'mse': 0.1       # MSEè¶Šå°è¶Šå¥½
            }
        
        score = 0.0
        total_weight = 0.0
        
        # LPIPSåˆ†æ•° (è¶Šå°è¶Šå¥½ï¼Œè½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½)
        if metrics.lpips is not None and 'lpips' in weights:
            lpips_score = max(0, 1.0 - metrics.lpips)  # å‡è®¾LPIPSé€šå¸¸åœ¨[0, 1]èŒƒå›´
            score += weights['lpips'] * lpips_score
            total_weight += weights['lpips']
        
        # SSIMåˆ†æ•° (è¶Šå¤§è¶Šå¥½)
        if metrics.ssim is not None and 'ssim' in weights:
            ssim_score = max(0, min(1, metrics.ssim))
            score += weights['ssim'] * ssim_score
            total_weight += weights['ssim']
        
        # PSNRåˆ†æ•° (è¶Šå¤§è¶Šå¥½ï¼Œéœ€è¦å½’ä¸€åŒ–)
        if metrics.psnr is not None and 'psnr' in weights:
            # PSNRé€šå¸¸åœ¨10-50dBèŒƒå›´ï¼Œå½’ä¸€åŒ–åˆ°[0,1]
            psnr_score = max(0, min(1, (metrics.psnr - 10) / 40))
            score += weights['psnr'] * psnr_score
            total_weight += weights['psnr']
        
        # MSEåˆ†æ•° (è¶Šå°è¶Šå¥½ï¼Œéœ€è¦è½¬æ¢)
        if metrics.mse is not None and 'mse' in weights:
            # MSEå½’ä¸€åŒ–æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œä½¿ç”¨ç®€å•çš„æŒ‡æ•°è¡°å‡
            mse_score = np.exp(-metrics.mse / 1000.0)  # è°ƒæ•´è¡°å‡å› å­
            score += weights['mse'] * mse_score
            total_weight += weights['mse']
        
        return score / total_weight if total_weight > 0 else 0.0
    
    def evaluate_single_pair(
        self,
        img1: Union[torch.Tensor, np.ndarray, str],
        img2: Union[torch.Tensor, np.ndarray, str],
        pair_id: str = "unknown"
    ) -> QualityEvaluationResult:
        """
        è¯„ä¼°å•å¯¹å›¾åƒ
        
        Args:
            img1: ç¬¬ä¸€å¼ å›¾åƒï¼ˆé€šå¸¸æ˜¯åŸå§‹å›¾åƒï¼‰
            img2: ç¬¬äºŒå¼ å›¾åƒï¼ˆé€šå¸¸æ˜¯å¤„ç†åå›¾åƒï¼‰
            pair_id: å›¾åƒå¯¹ID
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        # é¢„å¤„ç†å›¾åƒ
        img1_np, img2_np, img1_tensor, img2_tensor = self.preprocess_images(img1, img2)
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        metrics = QualityMetrics()
        
        # LPIPS
        if self.compute_lpips:
            metrics.lpips = self._compute_lpips(img1_tensor, img2_tensor)
        
        # ä¼ ç»ŸæŒ‡æ ‡
        metrics.psnr = self.compute_psnr(img1_np, img2_np)
        metrics.ssim = self.compute_ssim(img1_np, img2_np)
        metrics.mse = self.compute_mse(img1_np, img2_np)
        metrics.mae = self.compute_mae(img1_np, img2_np)
        
        # ç»“æ„ç›¸ä¼¼æ€§ï¼ˆä½¿ç”¨SSIMï¼‰
        metrics.structural_similarity = metrics.ssim
        
        # æ„ŸçŸ¥è·ç¦»ï¼ˆä½¿ç”¨LPIPSï¼‰
        metrics.perceptual_distance = metrics.lpips
        
        # ç»¼åˆåˆ†æ•°
        metrics.overall_score = self.compute_overall_score(metrics)
        
        # åˆ›å»ºç»“æœ
        result = QualityEvaluationResult(
            image_pair_id=pair_id,
            metrics=metrics,
            image_size=(img1_np.shape[1], img1_np.shape[0]),  # (width, height)
            color_channels=img1_np.shape[2] if len(img1_np.shape) == 3 else 1,
            metadata={
                "evaluation_timestamp": datetime.now().isoformat(),
                "evaluator_device": self.device,
                "compute_lpips": self.compute_lpips
            }
        )
        
        return result
    
    def evaluate_batch(
        self,
        image_pairs: List[Tuple[Union[torch.Tensor, np.ndarray, str], Union[torch.Tensor, np.ndarray, str]]],
        pair_ids: Optional[List[str]] = None
    ) -> List[QualityEvaluationResult]:
        """
        æ‰¹é‡è¯„ä¼°å›¾åƒå¯¹
        
        Args:
            image_pairs: å›¾åƒå¯¹åˆ—è¡¨
            pair_ids: å›¾åƒå¯¹IDåˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœåˆ—è¡¨
        """
        if pair_ids is None:
            pair_ids = [f"pair_{i:03d}" for i in range(len(image_pairs))]
        
        results = []
        
        for i, (img1, img2) in enumerate(image_pairs):
            try:
                result = self.evaluate_single_pair(img1, img2, pair_ids[i])
                results.append(result)
                logger.info(f"è¯„ä¼°å®Œæˆ: {pair_ids[i]} - LPIPS={result.metrics.lpips:.4f if result.metrics.lpips else 'N/A'}, SSIM={result.metrics.ssim:.4f if result.metrics.ssim else 'N/A'}")
            except Exception as e:
                logger.error(f"è¯„ä¼°å¤±è´¥ {pair_ids[i]}: {e}")
                continue
        
        return results
    
    def analyze_quality_statistics(
        self,
        results: List[QualityEvaluationResult]
    ) -> Dict[str, Dict[str, float]]:
        """
        åˆ†æè´¨é‡ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            results: è¯„ä¼°ç»“æœåˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not results:
            return {}
        
        # æå–å„é¡¹æŒ‡æ ‡
        metrics_data = {
            'lpips': [r.metrics.lpips for r in results if r.metrics.lpips is not None],
            'psnr': [r.metrics.psnr for r in results if r.metrics.psnr is not None],
            'ssim': [r.metrics.ssim for r in results if r.metrics.ssim is not None],
            'mse': [r.metrics.mse for r in results if r.metrics.mse is not None],
            'mae': [r.metrics.mae for r in results if r.metrics.mae is not None],
            'overall_score': [r.metrics.overall_score for r in results if r.metrics.overall_score is not None]
        }
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        statistics = {}
        for metric_name, values in metrics_data.items():
            if values:
                statistics[metric_name] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'median': np.median(values),
                    'count': len(values)
                }
            else:
                statistics[metric_name] = {
                    'mean': None, 'std': None, 'min': None,
                    'max': None, 'median': None, 'count': 0
                }
        
        return statistics
    
    def generate_quality_report(
        self,
        results: List[QualityEvaluationResult],
        statistics: Dict[str, Dict[str, float]] = None,
        save_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆè´¨é‡è¯„ä¼°æŠ¥å‘Š
        
        Args:
            results: è¯„ä¼°ç»“æœåˆ—è¡¨
            statistics: ç»Ÿè®¡ä¿¡æ¯
            save_path: ä¿å­˜è·¯å¾„
            
        Returns:
            å®Œæ•´æŠ¥å‘Š
        """
        if statistics is None:
            statistics = self.analyze_quality_statistics(results)
        
        report = {
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "evaluator_config": {
                    "device": self.device,
                    "compute_lpips": self.compute_lpips
                },
                "total_pairs": len(results)
            },
            "statistics": statistics,
            "individual_results": [],
            "summary": {}
        }
        
        # ä¸ªåˆ«ç»“æœ
        for result in results:
            report["individual_results"].append({
                "pair_id": result.image_pair_id,
                "metrics": {
                    "lpips": result.metrics.lpips,
                    "psnr": result.metrics.psnr,
                    "ssim": result.metrics.ssim,
                    "mse": result.metrics.mse,
                    "mae": result.metrics.mae,
                    "overall_score": result.metrics.overall_score
                },
                "image_info": {
                    "size": result.image_size,
                    "channels": result.color_channels
                }
            })
        
        # æ‘˜è¦
        if statistics:
            report["summary"] = {
                "quality_rating": self._rate_quality(statistics),
                "recommendations": self._generate_quality_recommendations(statistics),
                "key_findings": self._extract_key_findings(statistics)
            }
        
        # ä¿å­˜æŠ¥å‘Š
        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"è´¨é‡è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")
        
        return report
    
    def _rate_quality(self, statistics: Dict[str, Dict[str, float]]) -> str:
        """è¯„ä¼°æ•´ä½“è´¨é‡ç­‰çº§"""
        overall_mean = statistics.get('overall_score', {}).get('mean')
        if overall_mean is None:
            return "Unknown"
        
        if overall_mean >= 0.8:
            return "Excellent"
        elif overall_mean >= 0.6:
            return "Good"
        elif overall_mean >= 0.4:
            return "Fair"
        elif overall_mean >= 0.2:
            return "Poor"
        else:
            return "Very Poor"
    
    def _generate_quality_recommendations(self, statistics: Dict[str, Dict[str, float]]) -> List[str]:
        """ç”Ÿæˆè´¨é‡æ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # LPIPSåˆ†æ
        lpips_mean = statistics.get('lpips', {}).get('mean')
        if lpips_mean is not None:
            if lpips_mean > 0.2:
                recommendations.append("LPIPSæ„ŸçŸ¥è·ç¦»è¾ƒé«˜ï¼Œå»ºè®®é™ä½ä¿æŠ¤å¼ºåº¦æˆ–ä¼˜åŒ–ç®—æ³•ä»¥æ”¹å–„æ„ŸçŸ¥è´¨é‡")
            elif lpips_mean < 0.05:
                recommendations.append("LPIPSæ„ŸçŸ¥è´¨é‡ä¼˜ç§€ï¼Œå¯è€ƒè™‘é€‚å½“å¢å¼ºä¿æŠ¤å¼ºåº¦")
        
        # SSIMåˆ†æ
        ssim_mean = statistics.get('ssim', {}).get('mean')
        if ssim_mean is not None:
            if ssim_mean < 0.8:
                recommendations.append("SSIMç»“æ„ç›¸ä¼¼æ€§åä½ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•ä»¥ä¿æŒå›¾åƒç»“æ„")
            elif ssim_mean > 0.95:
                recommendations.append("SSIMç»“æ„ç›¸ä¼¼æ€§å¾ˆé«˜ï¼Œä¿æŠ¤æ•ˆæœå¯èƒ½ä¸è¶³")
        
        # PSNRåˆ†æ
        psnr_mean = statistics.get('psnr', {}).get('mean')
        if psnr_mean is not None:
            if psnr_mean < 20:
                recommendations.append("PSNRä¿¡å™ªæ¯”åä½ï¼Œå»ºè®®å‡å°‘å›¾åƒå¤±çœŸ")
            elif psnr_mean > 40:
                recommendations.append("PSNRä¿¡å™ªæ¯”å¾ˆé«˜ï¼Œå¯è€ƒè™‘å¢å¼ºä¿æŠ¤å¼ºåº¦")
        
        if not recommendations:
            recommendations.append("å›¾åƒè´¨é‡æŒ‡æ ‡å‡åœ¨åˆç†èŒƒå›´å†…")
        
        return recommendations
    
    def _extract_key_findings(self, statistics: Dict[str, Dict[str, float]]) -> List[str]:
        """æå–å…³é”®å‘ç°"""
        findings = []
        
        for metric_name, stats in statistics.items():
            if stats['count'] > 0:
                findings.append(
                    f"{metric_name.upper()}: å¹³å‡={stats['mean']:.4f}, "
                    f"æ ‡å‡†å·®={stats['std']:.4f}, èŒƒå›´=[{stats['min']:.4f}, {stats['max']:.4f}]"
                )
        
        return findings
    
    def plot_quality_metrics(
        self,
        results: List[QualityEvaluationResult],
        save_path: Optional[str] = None
    ):
        """
        ç»˜åˆ¶è´¨é‡æŒ‡æ ‡å›¾è¡¨
        
        Args:
            results: è¯„ä¼°ç»“æœåˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        if not results:
            logger.warning("æ²¡æœ‰ç»“æœå¯ç»˜åˆ¶")
            return
        
        # æå–æŒ‡æ ‡æ•°æ®
        metrics_data = {}
        valid_metrics = []
        
        if any(r.metrics.lpips is not None for r in results):
            metrics_data['LPIPS'] = [r.metrics.lpips for r in results if r.metrics.lpips is not None]
            valid_metrics.append('LPIPS')
        
        if any(r.metrics.ssim is not None for r in results):
            metrics_data['SSIM'] = [r.metrics.ssim for r in results if r.metrics.ssim is not None]
            valid_metrics.append('SSIM')
        
        if any(r.metrics.psnr is not None for r in results):
            metrics_data['PSNR'] = [r.metrics.psnr for r in results if r.metrics.psnr is not None]
            valid_metrics.append('PSNR')
        
        if any(r.metrics.overall_score is not None for r in results):
            metrics_data['Overall Score'] = [r.metrics.overall_score for r in results if r.metrics.overall_score is not None]
            valid_metrics.append('Overall Score')
        
        # åˆ›å»ºå­å›¾
        n_metrics = len(valid_metrics)
        if n_metrics == 0:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        for i, metric in enumerate(valid_metrics[:4]):
            if i < len(axes):
                data = metrics_data[metric]
                
                # ç›´æ–¹å›¾
                axes[i].hist(data, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
                axes[i].set_title(f'{metric} Distribution')
                axes[i].set_xlabel(metric)
                axes[i].set_ylabel('Frequency')
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                mean_val = np.mean(data)
                std_val = np.std(data)
                axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.3f}')
                axes[i].axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.7, label=f'+1Ïƒ: {mean_val + std_val:.3f}')
                axes[i].axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.7, label=f'-1Ïƒ: {mean_val - std_val:.3f}')
                axes[i].legend()
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(valid_metrics), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"è´¨é‡æŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.close()

def create_image_quality_evaluator(
    lpips_net: str = "alex",
    device: str = None,
    **kwargs
) -> ImageQualityEvaluator:
    """
    åˆ›å»ºå›¾åƒè´¨é‡è¯„ä¼°å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        lpips_net: LPIPSç½‘ç»œç±»å‹
        device: è®¾å¤‡
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        è´¨é‡è¯„ä¼°å™¨å®ä¾‹
    """
    return ImageQualityEvaluator(
        lpips_net=lpips_net,
        device=device,
        **kwargs
    )

def test_image_quality_evaluator():
    """æµ‹è¯•å›¾åƒè´¨é‡è¯„ä¼°å™¨"""
    print("ğŸ§ª æµ‹è¯•å›¾åƒè´¨é‡è¯„ä¼°å™¨...")
    
    try:
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = create_image_quality_evaluator()
        
        print(f"âœ… è´¨é‡è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   è®¾å¤‡: {evaluator.device}")
        print(f"   LPIPSæ”¯æŒ: {evaluator.compute_lpips}")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        np.random.seed(42)
        
        # åŸå§‹å›¾åƒ
        original_img = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        
        # æ¨¡æ‹Ÿä¿æŠ¤åçš„å›¾åƒï¼ˆæ·»åŠ ä¸€äº›å™ªå£°ï¼‰
        noise = np.random.normal(0, 10, original_img.shape).astype(np.int16)
        protected_img = np.clip(original_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)
        
        print("ğŸ”® æµ‹è¯•å•å¯¹å›¾åƒè¯„ä¼°...")
        
        # è¯„ä¼°å•å¯¹å›¾åƒ
        result = evaluator.evaluate_single_pair(original_img, protected_img, "test_pair")
        
        print(f"âœ… å•å¯¹è¯„ä¼°æˆåŠŸ:")
        if result.metrics.lpips is not None:
            print(f"   LPIPS: {result.metrics.lpips:.4f}")
        if result.metrics.psnr is not None:
            print(f"   PSNR: {result.metrics.psnr:.2f} dB")
        if result.metrics.ssim is not None:
            print(f"   SSIM: {result.metrics.ssim:.4f}")
        if result.metrics.mse is not None:
            print(f"   MSE: {result.metrics.mse:.2f}")
        if result.metrics.overall_score is not None:
            print(f"   ç»¼åˆåˆ†æ•°: {result.metrics.overall_score:.4f}")
        
        # æµ‹è¯•æ‰¹é‡è¯„ä¼°
        print("ğŸ“Š æµ‹è¯•æ‰¹é‡è¯„ä¼°...")
        
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•å›¾åƒå¯¹
        image_pairs = []
        for i in range(5):
            # ç”Ÿæˆä¸åŒç¨‹åº¦çš„å¤±çœŸ
            noise_level = (i + 1) * 5
            noise = np.random.normal(0, noise_level, original_img.shape).astype(np.int16)
            distorted_img = np.clip(original_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)
            image_pairs.append((original_img, distorted_img))
        
        batch_results = evaluator.evaluate_batch(image_pairs)
        
        print(f"âœ… æ‰¹é‡è¯„ä¼°æˆåŠŸ: {len(batch_results)}å¯¹å›¾åƒ")
        
        # æµ‹è¯•ç»Ÿè®¡åˆ†æ
        print("ğŸ“ˆ æµ‹è¯•ç»Ÿè®¡åˆ†æ...")
        statistics = evaluator.analyze_quality_statistics(batch_results)
        
        for metric_name, stats in statistics.items():
            if stats['count'] > 0:
                print(f"   {metric_name}: å¹³å‡={stats['mean']:.4f}, æ ‡å‡†å·®={stats['std']:.4f}")
        
        # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ...")
        report = evaluator.generate_quality_report(batch_results, statistics)
        
        print(f"âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ:")
        print(f"   è¯„ä¼°å¯¹æ•°: {report['metadata']['total_pairs']}")
        print(f"   è´¨é‡è¯„çº§: {report['summary']['quality_rating']}")
        print(f"   å»ºè®®æ•°é‡: {len(report['summary']['recommendations'])}")
        
        print("ğŸ‰ å›¾åƒè´¨é‡è¯„ä¼°å™¨æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_image_quality_evaluator() 