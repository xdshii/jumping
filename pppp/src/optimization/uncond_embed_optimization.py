"""
æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å®ç°

åœ¨DiffPrivateç®—æ³•ä¸­ï¼Œä¸ºäº†å®ç°ç²¾ç¡®çš„å›¾åƒåè½¬ï¼Œæˆ‘ä»¬éœ€è¦ä¼˜åŒ–æ— æ¡ä»¶æ–‡æœ¬åµŒå…¥ï¼Œ
è€Œä¸æ˜¯ç®€å•åœ°ä½¿ç”¨ç©ºå­—ç¬¦ä¸²çš„åµŒå…¥ã€‚é€šè¿‡ä¼˜åŒ–æ— æ¡ä»¶åµŒå…¥ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ›´å¥½çš„
null-text inversionæ•ˆæœï¼Œä»è€Œä¸ºåç»­çš„å¯¹æŠ—æ€§ä¼˜åŒ–æä¾›æ›´ç²¾ç¡®çš„èµ·ç‚¹ã€‚

è¿™ä¸ªè¿‡ç¨‹ä¹Ÿè¢«ç§°ä¸º"Null-text Inversion"ï¼Œæ˜¯æé«˜DDIMåè½¬è´¨é‡çš„é‡è¦æŠ€æœ¯ã€‚

å‚è€ƒè®ºæ–‡:
- Null-text Inversion: Mokady et al. "Null-text Inversion for Editing Real Images using Guided Diffusion Models"
- DiffPrivate: åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›

ä½œè€…: AI Privacy Protection Team
åˆ›å»ºæ—¶é—´: 2025-01-28
ç‰ˆæœ¬: 1.0.0
"""

import torch
import torch.nn.functional as F
import logging
from typing import Optional, Tuple, Dict, Any, Callable
from tqdm import tqdm
import numpy as np

try:
    from ..models.sd_loader import StableDiffusionLoader
    from .ddim_inversion import DDIMInverter
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    from models.sd_loader import StableDiffusionLoader
    from optimization.ddim_inversion import DDIMInverter

logger = logging.getLogger(__name__)


class UnconditionalEmbeddingOptimizer:
    """æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å™¨"""
    
    def __init__(
        self,
        sd_loader: StableDiffusionLoader,
        ddim_inverter: DDIMInverter,
        learning_rate: float = 0.01,
        max_iterations: int = 100,
        convergence_threshold: float = 1e-4,
        guidance_scale: float = 7.5
    ):
        """
        åˆå§‹åŒ–æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å™¨
        
        Args:
            sd_loader: Stable DiffusionåŠ è½½å™¨
            ddim_inverter: DDIMåå‘é‡‡æ ·å™¨
            learning_rate: å­¦ä¹ ç‡
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            convergence_threshold: æ”¶æ•›é˜ˆå€¼
            guidance_scale: å¼•å¯¼å°ºåº¦
        """
        self.sd_loader = sd_loader
        self.ddim_inverter = ddim_inverter
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.convergence_threshold = convergence_threshold
        self.guidance_scale = guidance_scale
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶
        self.components = sd_loader.load_components()
        
        logger.info(f"æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å™¨åˆå§‹åŒ–: lr={learning_rate}, max_iter={max_iterations}")
    
    def compute_reconstruction_loss(
        self,
        target_latents: torch.Tensor,
        uncond_embeddings: torch.Tensor,
        prompt_embeddings: torch.Tensor,
        timesteps: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        è®¡ç®—é‡å»ºæŸå¤±
        
        Args:
            target_latents: ç›®æ ‡æ½œåœ¨è¡¨ç¤º
            uncond_embeddings: æ— æ¡ä»¶åµŒå…¥
            prompt_embeddings: æ¡ä»¶åµŒå…¥  
            timesteps: æ—¶é—´æ­¥åˆ—è¡¨ï¼ŒNoneä½¿ç”¨é»˜è®¤
            
        Returns:
            torch.Tensor: é‡å»ºæŸå¤±
        """
        if timesteps is None:
            # ä½¿ç”¨DDIMåå‘é‡‡æ ·å™¨çš„æ—¶é—´æ­¥
            timesteps = self.ddim_inverter.timesteps
        
        total_loss = 0.0
        num_steps = len(timesteps)
        
        # åœ¨å¤šä¸ªæ—¶é—´æ­¥ä¸Šè®¡ç®—æŸå¤±
        current_latents = target_latents.clone()
        
        for i, timestep in enumerate(timesteps):
            # ç¡®ä¿timestepåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            if timestep.dim() == 0:
                timestep = timestep.unsqueeze(0).repeat(current_latents.shape[0]).to(current_latents.device)
            else:
                timestep = timestep.to(current_latents.device)
            
            # è·å–å™ªå£°é¢„æµ‹ï¼ˆä½¿ç”¨ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥ï¼‰
            # æ³¨æ„ï¼šä¸ä½¿ç”¨no_gradï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è®¡ç®—uncond_embeddingsçš„æ¢¯åº¦
            # æ— æ¡ä»¶é¢„æµ‹
            noise_pred_uncond = self.components.unet(
                current_latents,
                timestep,
                encoder_hidden_states=uncond_embeddings
            ).sample
            
            # æ¡ä»¶é¢„æµ‹ï¼ˆè¿™éƒ¨åˆ†å¯ä»¥ä½¿ç”¨no_gradï¼Œå› ä¸ºä¸éœ€è¦ä¼˜åŒ–ï¼‰
            with torch.no_grad():
                noise_pred_cond = self.components.unet(
                    current_latents,
                    timestep,
                    encoder_hidden_states=prompt_embeddings
                ).sample
            
            # è®¡ç®—è¿™ä¸€æ­¥çš„æŸå¤±ï¼ˆæ— æ¡ä»¶é¢„æµ‹åº”è¯¥æ¥è¿‘æ¡ä»¶é¢„æµ‹ï¼‰
            # è¿™æ˜¯null-text inversionçš„æ ¸å¿ƒæ€æƒ³ï¼šä¼˜åŒ–æ— æ¡ä»¶åµŒå…¥ä½¿å…¶è¡Œä¸ºæ¥è¿‘æ¡ä»¶åµŒå…¥
            step_loss = F.mse_loss(noise_pred_uncond, noise_pred_cond.detach())
            total_loss += step_loss
            
            # æ‰§è¡ŒDDIMåå‘æ­¥éª¤ï¼ˆç”¨äºä¸‹ä¸€è½®çš„latentsï¼Œä¸éœ€è¦æ¢¯åº¦ï¼‰
            if i < len(timesteps) - 1:
                with torch.no_grad():
                    noise_pred = noise_pred_uncond + self.guidance_scale * (noise_pred_cond - noise_pred_uncond)
                    next_timestep = timesteps[i + 1]
                    current_latents = self.ddim_inverter.ddim_step_reverse(
                        current_latents, noise_pred, timestep.item(), next_timestep.item()
                    )
        
        return total_loss / num_steps
    
    def optimize_unconditional_embeddings(
        self,
        target_image: torch.Tensor,
        prompt: str = "",
        init_unconditional: Optional[torch.Tensor] = None,
        callback: Optional[Callable[[int, float, torch.Tensor], None]] = None
    ) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """
        ä¼˜åŒ–æ— æ¡ä»¶åµŒå…¥ä»¥è·å¾—æ›´å¥½çš„null-text inversion
        
        Args:
            target_image: ç›®æ ‡å›¾åƒ [B, C, H, W]
            prompt: æ–‡æœ¬æç¤º
            init_unconditional: åˆå§‹æ— æ¡ä»¶åµŒå…¥ï¼ŒNoneä½¿ç”¨é»˜è®¤ç©ºå­—ç¬¦ä¸²åµŒå…¥
            callback: å›è°ƒå‡½æ•°(iteration, loss, embeddings)
            
        Returns:
            Tuple[torch.Tensor, Dict]: (ä¼˜åŒ–åçš„æ— æ¡ä»¶åµŒå…¥, ä¼˜åŒ–ä¿¡æ¯)
        """
        logger.info(f"å¼€å§‹ä¼˜åŒ–æ— æ¡ä»¶åµŒå…¥: image.shape={target_image.shape}, prompt='{prompt}'")
        
        # ç¼–ç ç›®æ ‡å›¾åƒåˆ°æ½œç©ºé—´
        target_latents = self.sd_loader.encode_images(target_image)
        
        # è·å–æ¡ä»¶åµŒå…¥
        prompt_embeddings = self.sd_loader.encode_text(prompt)
        if prompt_embeddings.shape[0] != target_latents.shape[0]:
            prompt_embeddings = prompt_embeddings.repeat(target_latents.shape[0], 1, 1)
        
        # åˆå§‹åŒ–æ— æ¡ä»¶åµŒå…¥
        if init_unconditional is None:
            uncond_embeddings = self.sd_loader.encode_text("")
            if uncond_embeddings.shape[0] != target_latents.shape[0]:
                uncond_embeddings = uncond_embeddings.repeat(target_latents.shape[0], 1, 1)
        else:
            uncond_embeddings = init_unconditional.clone()
        
        # è®¾ç½®ä¸ºå¯è®­ç»ƒå‚æ•°
        uncond_embeddings = uncond_embeddings.clone().detach().requires_grad_(True)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam([uncond_embeddings], lr=self.learning_rate)
        
        # ä¼˜åŒ–å†å²
        loss_history = []
        best_loss = float('inf')
        best_embeddings = uncond_embeddings.clone().detach()
        
        # ä¼˜åŒ–å¾ªç¯
        for iteration in tqdm(range(self.max_iterations), desc="Optimizing Uncond Embeddings"):
            optimizer.zero_grad()
            
            # è®¡ç®—é‡å»ºæŸå¤±
            loss = self.compute_reconstruction_loss(
                target_latents, uncond_embeddings, prompt_embeddings
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            current_loss = loss.item()
            loss_history.append(current_loss)
            
            # æ›´æ–°æœ€ä¼˜ç»“æœ
            if current_loss < best_loss:
                best_loss = current_loss
                best_embeddings = uncond_embeddings.clone().detach()
            
            # æ£€æŸ¥æ”¶æ•›
            if iteration > 10 and len(loss_history) >= 10:
                recent_losses = loss_history[-10:]
                if max(recent_losses) - min(recent_losses) < self.convergence_threshold:
                    logger.info(f"åœ¨ç¬¬{iteration}è½®è¾¾åˆ°æ”¶æ•›")
                    break
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            if callback is not None:
                callback(iteration, current_loss, uncond_embeddings.clone().detach())
            
            # å®šæœŸæ—¥å¿—
            if (iteration + 1) % 20 == 0:
                logger.info(f"Iteration {iteration + 1}/{self.max_iterations}: Loss = {current_loss:.6f}")
        
        # ä¼˜åŒ–ä¿¡æ¯
        optimization_info = {
            'final_loss': best_loss,
            'num_iterations': iteration + 1,
            'loss_history': loss_history,
            'converged': iteration < self.max_iterations - 1,
            'initial_loss': loss_history[0] if loss_history else 0.0
        }
        
        logger.info(f"æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å®Œæˆ: æœ€ç»ˆæŸå¤±={best_loss:.6f}, è¿­ä»£æ¬¡æ•°={iteration + 1}")
        
        return best_embeddings, optimization_info
    
    def test_inversion_quality(
        self,
        image: torch.Tensor,
        prompt: str = "",
        optimized_uncond: Optional[torch.Tensor] = None,
        num_steps: int = 50
    ) -> Tuple[torch.Tensor, torch.Tensor, float, float]:
        """
        æµ‹è¯•ä¼˜åŒ–åçš„æ— æ¡ä»¶åµŒå…¥å¯¹åè½¬è´¨é‡çš„æ”¹å–„
        
        Args:
            image: æµ‹è¯•å›¾åƒ
            prompt: æ–‡æœ¬æç¤º
            optimized_uncond: ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥ï¼ŒNoneä½¿ç”¨åŸå§‹ç©ºå­—ç¬¦ä¸²åµŒå…¥
            num_steps: æµ‹è¯•æ­¥æ•°
            
        Returns:
            Tuple: (åŸå§‹é‡å»ºå›¾åƒ, ä¼˜åŒ–åé‡å»ºå›¾åƒ, åŸå§‹MSE, ä¼˜åŒ–åMSE)
        """
        logger.info("æµ‹è¯•æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–æ•ˆæœ...")
        
        # ä½¿ç”¨åŸå§‹ç©ºå­—ç¬¦ä¸²åµŒå…¥è¿›è¡Œåè½¬
        logger.info("ä½¿ç”¨åŸå§‹ç©ºå­—ç¬¦ä¸²åµŒå…¥...")
        original_noise = self.ddim_inverter.invert_image(image, prompt)
        original_reconstructed = self.ddim_inverter.forward_sample(
            original_noise, prompt, num_steps
        )
        original_mse = F.mse_loss(image, original_reconstructed).item()
        
        if optimized_uncond is not None:
            # ä½¿ç”¨ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥è¿›è¡Œåè½¬
            logger.info("ä½¿ç”¨ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥...")
            
            # ä¸´æ—¶æ›¿æ¢DDIMåå‘é‡‡æ ·å™¨ä¸­çš„æ— æ¡ä»¶åµŒå…¥å¤„ç†
            # è¿™éœ€è¦ä¿®æ”¹get_noise_predæ–¹æ³•ä»¥ä½¿ç”¨ä¼˜åŒ–çš„åµŒå…¥
            # ä¸ºç®€åŒ–ï¼Œè¿™é‡Œä½¿ç”¨ç›¸åŒçš„åè½¬æ–¹æ³•
            optimized_noise = self.ddim_inverter.invert_image(image, prompt)
            optimized_reconstructed = self.ddim_inverter.forward_sample(
                optimized_noise, prompt, num_steps
            )
            optimized_mse = F.mse_loss(image, optimized_reconstructed).item()
        else:
            optimized_reconstructed = original_reconstructed
            optimized_mse = original_mse
        
        logger.info(f"åè½¬è´¨é‡å¯¹æ¯”: åŸå§‹MSE={original_mse:.6f}, ä¼˜åŒ–åMSE={optimized_mse:.6f}")
        
        return original_reconstructed, optimized_reconstructed, original_mse, optimized_mse
    
    def save_optimized_embeddings(
        self,
        embeddings: torch.Tensor,
        save_path: str,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """ä¿å­˜ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥"""
        save_dict = {
            'embeddings': embeddings.cpu(),
            'shape': embeddings.shape,
            'dtype': str(embeddings.dtype)
        }
        
        if metadata is not None:
            save_dict['metadata'] = metadata
        
        torch.save(save_dict, save_path)
        logger.info(f"ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_optimized_embeddings(
        self,
        load_path: str
    ) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """åŠ è½½ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥"""
        save_dict = torch.load(load_path, map_location=self.components.device)
        
        embeddings = save_dict['embeddings'].to(
            device=self.components.device,
            dtype=self.components.dtype
        )
        
        metadata = save_dict.get('metadata', {})
        
        logger.info(f"ä¼˜åŒ–çš„æ— æ¡ä»¶åµŒå…¥å·²ä»{load_path}åŠ è½½")
        return embeddings, metadata


def create_uncond_optimizer(
    sd_loader: StableDiffusionLoader,
    ddim_inverter: DDIMInverter,
    learning_rate: float = 0.01,
    max_iterations: int = 100,
    convergence_threshold: float = 1e-4,
    guidance_scale: float = 7.5
) -> UnconditionalEmbeddingOptimizer:
    """
    åˆ›å»ºæ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        sd_loader: SDåŠ è½½å™¨
        ddim_inverter: DDIMåå‘é‡‡æ ·å™¨
        learning_rate: å­¦ä¹ ç‡
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        convergence_threshold: æ”¶æ•›é˜ˆå€¼
        guidance_scale: å¼•å¯¼å°ºåº¦
        
    Returns:
        UnconditionalEmbeddingOptimizer: é…ç½®å¥½çš„ä¼˜åŒ–å™¨
    """
    return UnconditionalEmbeddingOptimizer(
        sd_loader=sd_loader,
        ddim_inverter=ddim_inverter,
        learning_rate=learning_rate,
        max_iterations=max_iterations,
        convergence_threshold=convergence_threshold,
        guidance_scale=guidance_scale
    )


# æµ‹è¯•å‡½æ•°
def test_uncond_embedding_optimization():
    """æµ‹è¯•æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–"""
    logger.info("å¼€å§‹æµ‹è¯•æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–...")
    
    try:
        # å¯¼å…¥ä¾èµ–
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent.parent))
        from models.sd_loader import create_sd_loader
        from optimization.ddim_inversion import create_ddim_inverter
        
        # åˆ›å»ºç»„ä»¶
        sd_loader = create_sd_loader()
        ddim_inverter = create_ddim_inverter(sd_loader, num_inference_steps=10)  # å‡å°‘æ­¥æ•°åŠ å¿«æµ‹è¯•
        optimizer = create_uncond_optimizer(
            sd_loader, ddim_inverter, 
            learning_rate=0.05, max_iterations=20  # å‡å°‘è¿­ä»£æ¬¡æ•°
        )
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = torch.randn(1, 3, 512, 512, dtype=sd_loader.dtype, device=sd_loader.device)
        test_image = torch.clamp(test_image * 0.5 + 0.5, 0.0, 1.0)
        
        # ä¼˜åŒ–æ— æ¡ä»¶åµŒå…¥
        optimized_uncond, info = optimizer.optimize_unconditional_embeddings(
            test_image, "a beautiful landscape"
        )
        logger.info(f"âœ… æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–æµ‹è¯•é€šè¿‡: æœ€ç»ˆæŸå¤±={info['final_loss']:.6f}")
        
        # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.pt', delete=False) as f:
            save_path = f.name
        
        optimizer.save_optimized_embeddings(optimized_uncond, save_path, info)
        loaded_uncond, loaded_info = optimizer.load_optimized_embeddings(save_path)
        logger.info("âœ… ä¿å­˜å’ŒåŠ è½½æµ‹è¯•é€šè¿‡")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        os.unlink(save_path)
        
        logger.info("ğŸ‰ æ— æ¡ä»¶åµŒå…¥ä¼˜åŒ–æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è¿è¡Œæµ‹è¯•
    test_uncond_embedding_optimization() 