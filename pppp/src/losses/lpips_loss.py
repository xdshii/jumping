"""
LPIPSæ„ŸçŸ¥æŸå¤±å‡½æ•°å®ç°

è¯¥æ¨¡å—æä¾›LPIPSï¼ˆLearned Perceptual Image Patch Similarityï¼‰æ„ŸçŸ¥æŸå¤±ï¼Œ
ç”¨äºä¿è¯å›¾åƒå˜æ¢åçš„è§†è§‰è´¨é‡ä¿æŒã€‚

åŠŸèƒ½åŒ…æ‹¬ï¼š
1. LPIPSç½‘ç»œåŠ è½½å’Œæ¨ç†
2. æ„ŸçŸ¥æŸå¤±è®¡ç®—
3. å¤šå°ºåº¦æ„ŸçŸ¥æŸå¤±
4. æ¢¯åº¦æ”¯æŒçš„å¯å¾®åˆ†å®ç°

åŸºäºDiffPrivateè®ºæ–‡ä¸­çš„ä¿çœŸåº¦æŸå¤±è®¾è®¡ã€‚

ä½œè€…: AI Privacy Protection System
æ—¥æœŸ: 2025-07-28
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import logging
from typing import Optional, Dict, Any, Union, List
import numpy as np

try:
    import lpips
    LPIPS_AVAILABLE = True
except ImportError:
    LPIPS_AVAILABLE = False
    logging.warning("LPIPSåº“ä¸å¯ç”¨ã€‚æ„ŸçŸ¥æŸå¤±åŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚")

logger = logging.getLogger(__name__)

class LPIPSLoss(nn.Module):
    """
    LPIPSæ„ŸçŸ¥æŸå¤±å‡½æ•°
    
    å®ç°åŸºäºå­¦ä¹ çš„æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§æŸå¤±ï¼Œç”¨äºè¡¡é‡å›¾åƒçš„æ„ŸçŸ¥è´¨é‡å·®å¼‚
    """
    
    def __init__(
        self,
        net: str = "alex",  # 'alex', 'vgg', 'squeeze'
        version: str = "0.1",
        use_gpu: bool = True,
        spatial_average: bool = True,
        pixel_loss_weight: float = 0.0,
        normalize_input: bool = True
    ):
        """
        åˆå§‹åŒ–LPIPSæŸå¤±å‡½æ•°
        
        Args:
            net: ä½¿ç”¨çš„ç½‘ç»œéª¨æ¶ ('alex', 'vgg', 'squeeze')
            version: LPIPSç‰ˆæœ¬
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            spatial_average: æ˜¯å¦å¯¹ç©ºé—´ç»´åº¦æ±‚å¹³å‡
            pixel_loss_weight: åƒç´ æŸå¤±æƒé‡ï¼ˆä¸LPIPSç»“åˆï¼‰
            normalize_input: æ˜¯å¦å¯¹è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–
        """
        super().__init__()
        
        if not LPIPS_AVAILABLE:
            raise ImportError("LPIPSåº“ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install lpips")
        
        self.net = net
        self.version = version
        self.use_gpu = use_gpu
        self.spatial_average = spatial_average
        self.pixel_loss_weight = pixel_loss_weight
        self.normalize_input = normalize_input
        
        # åˆå§‹åŒ–LPIPSç½‘ç»œ
        self.lpips_net = lpips.LPIPS(
            net=net,
            version=version,
            spatial=not spatial_average  # spatial=Trueè¿”å›ç©ºé—´å›¾ï¼ŒFalseè¿”å›æ ‡é‡
        )
        
        if use_gpu and torch.cuda.is_available():
            self.lpips_net = self.lpips_net.cuda()
        
        # å†»ç»“LPIPSç½‘ç»œå‚æ•°
        for param in self.lpips_net.parameters():
            param.requires_grad = False
        
        logger.info(f"LPIPSæŸå¤±åˆå§‹åŒ–: net={net}, version={version}, spatial_avg={spatial_average}")
    
    def preprocess_images(
        self,
        images: torch.Tensor
    ) -> torch.Tensor:
        """
        é¢„å¤„ç†å›¾åƒç”¨äºLPIPSè®¡ç®—
        
        Args:
            images: è¾“å…¥å›¾åƒ [batch_size, 3, H, W]ï¼Œå€¼åŸŸ[0,1]æˆ–[-1,1]
            
        Returns:
            é¢„å¤„ç†åçš„å›¾åƒ
        """
        # LPIPSæœŸæœ›è¾“å…¥èŒƒå›´ä¸º[-1, 1]
        if self.normalize_input:
            if images.min() >= 0:  # å¦‚æœè¾“å…¥æ˜¯[0,1]
                images = images * 2.0 - 1.0  # è½¬æ¢ä¸º[-1,1]
        
        return images
    
    def compute_pixel_loss(
        self,
        img1: torch.Tensor,
        img2: torch.Tensor,
        loss_type: str = "l2"
    ) -> torch.Tensor:
        """
        è®¡ç®—åƒç´ çº§æŸå¤±
        
        Args:
            img1: ç¬¬ä¸€å¼ å›¾åƒ
            img2: ç¬¬äºŒå¼ å›¾åƒ
            loss_type: æŸå¤±ç±»å‹ ('l1', 'l2', 'mse')
            
        Returns:
            åƒç´ æŸå¤±
        """
        if loss_type == "l1":
            return F.l1_loss(img1, img2, reduction='mean')
        elif loss_type in ["l2", "mse"]:
            return F.mse_loss(img1, img2, reduction='mean')
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åƒç´ æŸå¤±ç±»å‹: {loss_type}")
    
    def forward(
        self,
        img1: torch.Tensor,
        img2: torch.Tensor,
        return_components: bool = False
    ) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—LPIPSæ„ŸçŸ¥æŸå¤±
        
        Args:
            img1: ç¬¬ä¸€å¼ å›¾åƒ [batch_size, 3, H, W]
            img2: ç¬¬äºŒå¼ å›¾åƒ [batch_size, 3, H, W]
            return_components: æ˜¯å¦è¿”å›æŸå¤±ç»„ä»¶
            
        Returns:
            LPIPSæŸå¤±æˆ–æŸå¤±å­—å…¸
        """
        # é¢„å¤„ç†å›¾åƒ
        img1_proc = self.preprocess_images(img1)
        img2_proc = self.preprocess_images(img2)
        
        # è®¡ç®—LPIPSæŸå¤±
        lpips_loss = self.lpips_net(img1_proc, img2_proc)
        
        # å¦‚æœspatial_average=Falseï¼Œéœ€è¦æ‰‹åŠ¨æ±‚å¹³å‡
        if not self.spatial_average:
            lpips_loss = lpips_loss.mean()
        else:
            lpips_loss = lpips_loss.mean()  # ç¡®ä¿æ˜¯æ ‡é‡
        
        # è®¡ç®—åƒç´ æŸå¤±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        pixel_loss = 0.0
        if self.pixel_loss_weight > 0:
            pixel_loss = self.compute_pixel_loss(img1, img2)
        
        # æ€»æŸå¤±
        total_loss = lpips_loss + self.pixel_loss_weight * pixel_loss
        
        if return_components:
            return {
                "total_loss": total_loss,
                "lpips_loss": lpips_loss,
                "pixel_loss": pixel_loss,
                "pixel_weight": self.pixel_loss_weight
            }
        else:
            return total_loss

class MultiScaleLPIPSLoss(nn.Module):
    """
    å¤šå°ºåº¦LPIPSæŸå¤±
    
    åœ¨å¤šä¸ªå°ºåº¦ä¸Šè®¡ç®—LPIPSæŸå¤±ï¼Œæä¾›æ›´å…¨é¢çš„æ„ŸçŸ¥è¯„ä¼°
    """
    
    def __init__(
        self,
        scales: List[float] = [1.0, 0.5, 0.25],
        weights: Optional[List[float]] = None,
        net: str = "alex",
        version: str = "0.1",
        use_gpu: bool = True,
        spatial_average: bool = True
    ):
        """
        åˆå§‹åŒ–å¤šå°ºåº¦LPIPSæŸå¤±
        
        Args:
            scales: å°ºåº¦åˆ—è¡¨
            weights: å„å°ºåº¦æƒé‡
            net: LPIPSç½‘ç»œ
            version: LPIPSç‰ˆæœ¬
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            spatial_average: æ˜¯å¦ç©ºé—´å¹³å‡
        """
        super().__init__()
        
        self.scales = scales
        self.weights = weights if weights is not None else [1.0] * len(scales)
        
        assert len(self.weights) == len(scales), "æƒé‡æ•°é‡å¿…é¡»ä¸å°ºåº¦æ•°é‡åŒ¹é…"
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.weights)
        self.weights = [w / total_weight for w in self.weights]
        
        # åˆ›å»ºLPIPSæŸå¤±
        self.lpips_loss = LPIPSLoss(
            net=net,
            version=version,
            use_gpu=use_gpu,
            spatial_average=spatial_average,
            normalize_input=True
        )
        
        logger.info(f"å¤šå°ºåº¦LPIPSæŸå¤±åˆå§‹åŒ–: scales={scales}, weights={self.weights}")
    
    def resize_images(
        self,
        images: torch.Tensor,
        scale: float
    ) -> torch.Tensor:
        """
        è°ƒæ•´å›¾åƒå°ºå¯¸
        
        Args:
            images: è¾“å…¥å›¾åƒ
            scale: ç¼©æ”¾æ¯”ä¾‹
            
        Returns:
            è°ƒæ•´åçš„å›¾åƒ
        """
        if scale == 1.0:
            return images
        
        _, _, h, w = images.shape
        new_h, new_w = int(h * scale), int(w * scale)
        
        return F.interpolate(
            images,
            size=(new_h, new_w),
            mode='bilinear',
            align_corners=False
        )
    
    def forward(
        self,
        img1: torch.Tensor,
        img2: torch.Tensor,
        return_components: bool = False
    ) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—å¤šå°ºåº¦LPIPSæŸå¤±
        
        Args:
            img1: ç¬¬ä¸€å¼ å›¾åƒ
            img2: ç¬¬äºŒå¼ å›¾åƒ  
            return_components: æ˜¯å¦è¿”å›ç»„ä»¶
            
        Returns:
            å¤šå°ºåº¦LPIPSæŸå¤±
        """
        total_loss = 0.0
        components = {}
        
        for i, (scale, weight) in enumerate(zip(self.scales, self.weights)):
            # è°ƒæ•´å›¾åƒå°ºå¯¸
            img1_scaled = self.resize_images(img1, scale)
            img2_scaled = self.resize_images(img2, scale)
            
            # è®¡ç®—è¯¥å°ºåº¦çš„LPIPSæŸå¤±
            scale_loss = self.lpips_loss(img1_scaled, img2_scaled)
            
            # åŠ æƒç´¯åŠ 
            weighted_loss = weight * scale_loss
            total_loss += weighted_loss
            
            if return_components:
                components[f"scale_{scale}_loss"] = scale_loss
                components[f"scale_{scale}_weight"] = weight
                components[f"scale_{scale}_weighted"] = weighted_loss
        
        if return_components:
            components["total_loss"] = total_loss
            return components
        else:
            return total_loss

def create_lpips_loss(
    net: str = "alex",
    version: str = "0.1",
    use_gpu: bool = True,
    spatial_average: bool = True,
    pixel_loss_weight: float = 0.0,
    multiscale: bool = False,
    scales: Optional[List[float]] = None,
    scale_weights: Optional[List[float]] = None
) -> Union[LPIPSLoss, MultiScaleLPIPSLoss]:
    """
    åˆ›å»ºLPIPSæŸå¤±å‡½æ•°çš„ä¾¿æ·å‡½æ•°
    
    Args:
        net: LPIPSç½‘ç»œ
        version: LPIPSç‰ˆæœ¬
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        spatial_average: æ˜¯å¦ç©ºé—´å¹³å‡
        pixel_loss_weight: åƒç´ æŸå¤±æƒé‡
        multiscale: æ˜¯å¦ä½¿ç”¨å¤šå°ºåº¦
        scales: å¤šå°ºåº¦åˆ—è¡¨
        scale_weights: å¤šå°ºåº¦æƒé‡
        
    Returns:
        LPIPSæŸå¤±å‡½æ•°å®ä¾‹
    """
    if multiscale:
        if scales is None:
            scales = [1.0, 0.5, 0.25]
        return MultiScaleLPIPSLoss(
            scales=scales,
            weights=scale_weights,
            net=net,
            version=version,
            use_gpu=use_gpu,
            spatial_average=spatial_average
        )
    else:
        return LPIPSLoss(
            net=net,
            version=version,
            use_gpu=use_gpu,
            spatial_average=spatial_average,
            pixel_loss_weight=pixel_loss_weight
        )

def test_lpips_loss():
    """æµ‹è¯•LPIPSæŸå¤±å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•LPIPSæŸå¤±å‡½æ•°...")
    
    try:
        if not LPIPS_AVAILABLE:
            print("âŒ LPIPSåº“ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        batch_size = 2
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        img1 = torch.rand(batch_size, 3, 256, 256, device=device, requires_grad=True)
        img2 = torch.rand(batch_size, 3, 256, 256, device=device, requires_grad=True)
        
        print(f"âœ… æµ‹è¯•ç¯å¢ƒ: è®¾å¤‡={device}, æ‰¹å¤§å°={batch_size}")
        
        # æµ‹è¯•åŸºç¡€LPIPSæŸå¤±
        print("ğŸ”® æµ‹è¯•åŸºç¡€LPIPSæŸå¤±...")
        lpips_loss = create_lpips_loss(
            net="alex",
            use_gpu=(device == "cuda"),
            pixel_loss_weight=0.1
        )
        
        loss_dict = lpips_loss(img1, img2, return_components=True)
        print("âœ… åŸºç¡€LPIPSæŸå¤±è®¡ç®—æˆåŠŸ:")
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.item():.6f}")
            else:
                print(f"   {key}: {value:.6f}")
        
        # æµ‹è¯•æ¢¯åº¦
        print("ğŸ“ˆ æµ‹è¯•æ¢¯åº¦è®¡ç®—...")
        total_loss = loss_dict["total_loss"]
        
        # æ¸…é™¤æ¢¯åº¦
        if img1.grad is not None:
            img1.grad.zero_()
        if img2.grad is not None:
            img2.grad.zero_()
        
        total_loss.backward()
        
        img1_grad_norm = img1.grad.norm().item() if img1.grad is not None else 0
        img2_grad_norm = img2.grad.norm().item() if img2.grad is not None else 0
        
        print(f"âœ… æ¢¯åº¦è®¡ç®—æˆåŠŸ:")
        print(f"   img1æ¢¯åº¦èŒƒæ•°: {img1_grad_norm:.6f}")
        print(f"   img2æ¢¯åº¦èŒƒæ•°: {img2_grad_norm:.6f}")
        
        # æµ‹è¯•å¤šå°ºåº¦LPIPSæŸå¤±
        print("ğŸ” æµ‹è¯•å¤šå°ºåº¦LPIPSæŸå¤±...")
        multiscale_lpips = create_lpips_loss(
            net="alex",
            use_gpu=(device == "cuda"),
            multiscale=True,
            scales=[1.0, 0.5],
            scale_weights=[0.7, 0.3]
        )
        
        # é‡æ–°åˆ›å»ºå›¾åƒï¼ˆé¿å…æ¢¯åº¦ç´¯ç§¯ï¼‰
        img1_new = torch.rand(batch_size, 3, 256, 256, device=device, requires_grad=True)
        img2_new = torch.rand(batch_size, 3, 256, 256, device=device, requires_grad=True)
        
        multiscale_dict = multiscale_lpips(img1_new, img2_new, return_components=True)
        print("âœ… å¤šå°ºåº¦LPIPSæŸå¤±è®¡ç®—æˆåŠŸ:")
        for key, value in multiscale_dict.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.item():.6f}")
            else:
                print(f"   {key}: {value:.6f}")
        
        # æµ‹è¯•å¤šå°ºåº¦æ¢¯åº¦
        multiscale_loss = multiscale_dict["total_loss"]
        multiscale_loss.backward()
        
        img1_ms_grad = img1_new.grad.norm().item() if img1_new.grad is not None else 0
        img2_ms_grad = img2_new.grad.norm().item() if img2_new.grad is not None else 0
        
        print(f"âœ… å¤šå°ºåº¦æ¢¯åº¦è®¡ç®—æˆåŠŸ:")
        print(f"   img1æ¢¯åº¦èŒƒæ•°: {img1_ms_grad:.6f}")
        print(f"   img2æ¢¯åº¦èŒƒæ•°: {img2_ms_grad:.6f}")
        
        print("ğŸ‰ LPIPSæŸå¤±å‡½æ•°æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_lpips_loss() 